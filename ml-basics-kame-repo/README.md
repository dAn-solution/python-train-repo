## 機械学習入門（かめさんブログ）

### １．機械学習とはなにか？何をしているのか？
### ２．線形回帰の損失関数をわかりやすく解説
### ３．最急降下法を図と数式で理解する
### ４．正規方程式を完全解説（導出あり）
### ５．scikit-learnを使って線型回帰モデルを構築する
### ６．線型回帰の係数の解釈の仕方（p値）
### ７．過学習と汎化性能を理解する
### ８．LOOCVについて解説
### ９．k-Fold Cross Validation（交差検証）を解説する
### 10．回帰モデルの評価指標を一挙に解説
 - MSE,RMSE,MAE,R-Squsred
### 11．多項式特徴量で線形を超える
### 12．Bias-Variance Tradeoff を完全に理解する
### 13．質的変数を説明変数として使う方法を解説
 - One-hot エンコーディングとダミー変数トラップ
### 14．正則化項を用いて特徴量を選択する（Lasso）
### 15．ｋＮＮ回帰（ｋ最近傍法）アルゴリズムをわかりやすく解説
### 16．分類タスクとロジスティック回帰をわかりやすく解説
### 17．ロジスティック回帰を多クラス分類に応用する
### 18．Pythonでロジスティック回帰をする
### 19．分類機の評価
 - TP,TN,FP,FNと混合行列を理解する
### 20．分類機の評価指標
### 21．F値とPrecisionとRecailのトレードオフを理解する
### 22．ROCとAUCを超わかりやすく解説
### 23．多クラス分類におけるROCとAUC
### 24．次元削減とは？PCA（主成分分析）を理解する
### 25．PCA（主成分分析）を使ってモデル構築する（MNISTを分類）
### 26．教師なし学習（クラスタリング）のK-meansをわかりやすく説明
### 27．階層クラスタリング（Hierarchical Clustering）をわかりやすく解説
### 28．回帰の決定木アルゴリズムを完全図解する
### 29．ジニ不純度と木の剪定を解説
### 30．アンサンブル学習を超わかりやすく解説
### 31．ランダムフォレストをわかりやすく解説
### 32．XGBoostの概要とPython実装をわかりやすく
### 33．LightGBMを超わかりやすく解説
### 34．
### 35．